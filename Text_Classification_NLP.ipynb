{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Text Classification NLP**"
      ],
      "metadata": {
        "id": "hhxatBBTwS8I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gender Identification"
      ],
      "metadata": {
        "id": "u60CTNdAuQbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gender_features(word):\n",
        "     return {'last_letter': word[-1]}\n",
        "gender_features('Vishnu')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsmI-Z2iuPDM",
        "outputId": "806d8420-c3da-4ca3-bb81-69eda6728bd2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'last_letter': 'u'}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gender_features(word):\n",
        "     return {'last_letter': word[-2]}\n",
        "gender_features('Vishnu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Knnja5ELoTui",
        "outputId": "b1cffc3d-018f-4157-9533-2dd2d17c8895"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'last_letter': 'n'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gender_features(word):\n",
        "     return {'last_letter': word[0]}\n",
        "gender_features('Vishnu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vg7E70RQohl1",
        "outputId": "9294fa6d-c93a-4933-f516-ff4f4b9a4ab2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'last_letter': 'V'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnkUiaYwuo9H",
        "outputId": "3baf0779-8e42-4bd8-98c0-2123e50f5b97"
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> all\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    Downloading collection 'all'\n",
            "       | \n",
            "       | Downloading package abc to /root/nltk_data...\n",
            "       |   Unzipping corpora/abc.zip.\n",
            "       | Downloading package alpino to /root/nltk_data...\n",
            "       |   Unzipping corpora/alpino.zip.\n",
            "       | Downloading package averaged_perceptron_tagger to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "       | Downloading package averaged_perceptron_tagger_ru to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/averaged_perceptron_tagger_ru.zip.\n",
            "       | Downloading package basque_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/basque_grammars.zip.\n",
            "       | Downloading package biocreative_ppi to /root/nltk_data...\n",
            "       |   Unzipping corpora/biocreative_ppi.zip.\n",
            "       | Downloading package bllip_wsj_no_aux to /root/nltk_data...\n",
            "       |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "       | Downloading package book_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/book_grammars.zip.\n",
            "       | Downloading package brown to /root/nltk_data...\n",
            "       |   Unzipping corpora/brown.zip.\n",
            "       | Downloading package brown_tei to /root/nltk_data...\n",
            "       |   Unzipping corpora/brown_tei.zip.\n",
            "       | Downloading package cess_cat to /root/nltk_data...\n",
            "       |   Unzipping corpora/cess_cat.zip.\n",
            "       | Downloading package cess_esp to /root/nltk_data...\n",
            "       |   Unzipping corpora/cess_esp.zip.\n",
            "       | Downloading package chat80 to /root/nltk_data...\n",
            "       |   Unzipping corpora/chat80.zip.\n",
            "       | Downloading package city_database to /root/nltk_data...\n",
            "       |   Unzipping corpora/city_database.zip.\n",
            "       | Downloading package cmudict to /root/nltk_data...\n",
            "       |   Unzipping corpora/cmudict.zip.\n",
            "       | Downloading package comparative_sentences to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping corpora/comparative_sentences.zip.\n",
            "       | Downloading package comtrans to /root/nltk_data...\n",
            "       | Downloading package conll2000 to /root/nltk_data...\n",
            "       |   Unzipping corpora/conll2000.zip.\n",
            "       | Downloading package conll2002 to /root/nltk_data...\n",
            "       |   Unzipping corpora/conll2002.zip.\n",
            "       | Downloading package conll2007 to /root/nltk_data...\n",
            "       | Downloading package crubadan to /root/nltk_data...\n",
            "       |   Unzipping corpora/crubadan.zip.\n",
            "       | Downloading package dependency_treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/dependency_treebank.zip.\n",
            "       | Downloading package dolch to /root/nltk_data...\n",
            "       |   Unzipping corpora/dolch.zip.\n",
            "       | Downloading package europarl_raw to /root/nltk_data...\n",
            "       |   Unzipping corpora/europarl_raw.zip.\n",
            "       | Downloading package extended_omw to /root/nltk_data...\n",
            "       | Downloading package floresta to /root/nltk_data...\n",
            "       |   Unzipping corpora/floresta.zip.\n",
            "       | Downloading package framenet_v15 to /root/nltk_data...\n",
            "       |   Unzipping corpora/framenet_v15.zip.\n",
            "       | Downloading package framenet_v17 to /root/nltk_data...\n",
            "       |   Unzipping corpora/framenet_v17.zip.\n",
            "       | Downloading package gazetteers to /root/nltk_data...\n",
            "       |   Unzipping corpora/gazetteers.zip.\n",
            "       | Downloading package genesis to /root/nltk_data...\n",
            "       |   Unzipping corpora/genesis.zip.\n",
            "       | Downloading package gutenberg to /root/nltk_data...\n",
            "       |   Unzipping corpora/gutenberg.zip.\n",
            "       | Downloading package ieer to /root/nltk_data...\n",
            "       |   Unzipping corpora/ieer.zip.\n",
            "       | Downloading package inaugural to /root/nltk_data...\n",
            "       |   Unzipping corpora/inaugural.zip.\n",
            "       | Downloading package indian to /root/nltk_data...\n",
            "       |   Unzipping corpora/indian.zip.\n",
            "       | Downloading package jeita to /root/nltk_data...\n",
            "       | Downloading package kimmo to /root/nltk_data...\n",
            "       |   Unzipping corpora/kimmo.zip.\n",
            "       | Downloading package knbc to /root/nltk_data...\n",
            "       | Downloading package large_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/large_grammars.zip.\n",
            "       | Downloading package lin_thesaurus to /root/nltk_data...\n",
            "       |   Unzipping corpora/lin_thesaurus.zip.\n",
            "       | Downloading package mac_morpho to /root/nltk_data...\n",
            "       |   Unzipping corpora/mac_morpho.zip.\n",
            "       | Downloading package machado to /root/nltk_data...\n",
            "       | Downloading package masc_tagged to /root/nltk_data...\n",
            "       | Downloading package maxent_ne_chunker to /root/nltk_data...\n",
            "       |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "       | Downloading package maxent_treebank_pos_tagger to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "       | Downloading package moses_sample to /root/nltk_data...\n",
            "       |   Unzipping models/moses_sample.zip.\n",
            "       | Downloading package movie_reviews to /root/nltk_data...\n",
            "       |   Unzipping corpora/movie_reviews.zip.\n",
            "       | Downloading package mte_teip5 to /root/nltk_data...\n",
            "       |   Unzipping corpora/mte_teip5.zip.\n",
            "       | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "       |   Unzipping misc/mwa_ppdb.zip.\n",
            "       | Downloading package names to /root/nltk_data...\n",
            "       |   Unzipping corpora/names.zip.\n",
            "       | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "       | Downloading package nonbreaking_prefixes to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "       | Downloading package nps_chat to /root/nltk_data...\n",
            "       |   Unzipping corpora/nps_chat.zip.\n",
            "       | Downloading package omw to /root/nltk_data...\n",
            "       | Downloading package omw-1.4 to /root/nltk_data...\n",
            "       | Downloading package opinion_lexicon to /root/nltk_data...\n",
            "       |   Unzipping corpora/opinion_lexicon.zip.\n",
            "       | Downloading package panlex_swadesh to /root/nltk_data...\n",
            "       | Downloading package paradigms to /root/nltk_data...\n",
            "       |   Unzipping corpora/paradigms.zip.\n",
            "       | Downloading package pe08 to /root/nltk_data...\n",
            "       |   Unzipping corpora/pe08.zip.\n",
            "       | Downloading package perluniprops to /root/nltk_data...\n",
            "       |   Unzipping misc/perluniprops.zip.\n",
            "       | Downloading package pil to /root/nltk_data...\n",
            "       |   Unzipping corpora/pil.zip.\n",
            "       | Downloading package pl196x to /root/nltk_data...\n",
            "       |   Unzipping corpora/pl196x.zip.\n",
            "       | Downloading package porter_test to /root/nltk_data...\n",
            "       |   Unzipping stemmers/porter_test.zip.\n",
            "       | Downloading package ppattach to /root/nltk_data...\n",
            "       |   Unzipping corpora/ppattach.zip.\n",
            "       | Downloading package problem_reports to /root/nltk_data...\n",
            "       |   Unzipping corpora/problem_reports.zip.\n",
            "       | Downloading package product_reviews_1 to /root/nltk_data...\n",
            "       |   Unzipping corpora/product_reviews_1.zip.\n",
            "       | Downloading package product_reviews_2 to /root/nltk_data...\n",
            "       |   Unzipping corpora/product_reviews_2.zip.\n",
            "       | Downloading package propbank to /root/nltk_data...\n",
            "       | Downloading package pros_cons to /root/nltk_data...\n",
            "       |   Unzipping corpora/pros_cons.zip.\n",
            "       | Downloading package ptb to /root/nltk_data...\n",
            "       |   Unzipping corpora/ptb.zip.\n",
            "       | Downloading package punkt to /root/nltk_data...\n",
            "       |   Unzipping tokenizers/punkt.zip.\n",
            "       | Downloading package qc to /root/nltk_data...\n",
            "       |   Unzipping corpora/qc.zip.\n",
            "       | Downloading package reuters to /root/nltk_data...\n",
            "       | Downloading package rslp to /root/nltk_data...\n",
            "       |   Unzipping stemmers/rslp.zip.\n",
            "       | Downloading package rte to /root/nltk_data...\n",
            "       |   Unzipping corpora/rte.zip.\n",
            "       | Downloading package sample_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/sample_grammars.zip.\n",
            "       | Downloading package semcor to /root/nltk_data...\n",
            "       | Downloading package senseval to /root/nltk_data...\n",
            "       |   Unzipping corpora/senseval.zip.\n",
            "       | Downloading package sentence_polarity to /root/nltk_data...\n",
            "       |   Unzipping corpora/sentence_polarity.zip.\n",
            "       | Downloading package sentiwordnet to /root/nltk_data...\n",
            "       |   Unzipping corpora/sentiwordnet.zip.\n",
            "       | Downloading package shakespeare to /root/nltk_data...\n",
            "       |   Unzipping corpora/shakespeare.zip.\n",
            "       | Downloading package sinica_treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/sinica_treebank.zip.\n",
            "       | Downloading package smultron to /root/nltk_data...\n",
            "       |   Unzipping corpora/smultron.zip.\n",
            "       | Downloading package snowball_data to /root/nltk_data...\n",
            "       | Downloading package spanish_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/spanish_grammars.zip.\n",
            "       | Downloading package state_union to /root/nltk_data...\n",
            "       |   Unzipping corpora/state_union.zip.\n",
            "       | Downloading package stopwords to /root/nltk_data...\n",
            "       |   Unzipping corpora/stopwords.zip.\n",
            "       | Downloading package subjectivity to /root/nltk_data...\n",
            "       |   Unzipping corpora/subjectivity.zip.\n",
            "       | Downloading package swadesh to /root/nltk_data...\n",
            "       |   Unzipping corpora/swadesh.zip.\n",
            "       | Downloading package switchboard to /root/nltk_data...\n",
            "       |   Unzipping corpora/switchboard.zip.\n",
            "       | Downloading package tagsets to /root/nltk_data...\n",
            "       |   Unzipping help/tagsets.zip.\n",
            "       | Downloading package timit to /root/nltk_data...\n",
            "       |   Unzipping corpora/timit.zip.\n",
            "       | Downloading package toolbox to /root/nltk_data...\n",
            "       |   Unzipping corpora/toolbox.zip.\n",
            "       | Downloading package treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/treebank.zip.\n",
            "       | Downloading package twitter_samples to /root/nltk_data...\n",
            "       |   Unzipping corpora/twitter_samples.zip.\n",
            "       | Downloading package udhr to /root/nltk_data...\n",
            "       |   Unzipping corpora/udhr.zip.\n",
            "       | Downloading package udhr2 to /root/nltk_data...\n",
            "       |   Unzipping corpora/udhr2.zip.\n",
            "       | Downloading package unicode_samples to /root/nltk_data...\n",
            "       |   Unzipping corpora/unicode_samples.zip.\n",
            "       | Downloading package universal_tagset to /root/nltk_data...\n",
            "       |   Unzipping taggers/universal_tagset.zip.\n",
            "       | Downloading package universal_treebanks_v20 to\n",
            "       |     /root/nltk_data...\n",
            "       | Downloading package vader_lexicon to /root/nltk_data...\n",
            "       | Downloading package verbnet to /root/nltk_data...\n",
            "       |   Unzipping corpora/verbnet.zip.\n",
            "       | Downloading package verbnet3 to /root/nltk_data...\n",
            "       |   Unzipping corpora/verbnet3.zip.\n",
            "       | Downloading package webtext to /root/nltk_data...\n",
            "       |   Unzipping corpora/webtext.zip.\n",
            "       | Downloading package wmt15_eval to /root/nltk_data...\n",
            "       |   Unzipping models/wmt15_eval.zip.\n",
            "       | Downloading package word2vec_sample to /root/nltk_data...\n",
            "       |   Unzipping models/word2vec_sample.zip.\n",
            "       | Downloading package wordnet to /root/nltk_data...\n",
            "       | Downloading package wordnet2021 to /root/nltk_data...\n",
            "       | Downloading package wordnet31 to /root/nltk_data...\n",
            "       | Downloading package wordnet_ic to /root/nltk_data...\n",
            "       |   Unzipping corpora/wordnet_ic.zip.\n",
            "       | Downloading package words to /root/nltk_data...\n",
            "       |   Unzipping corpora/words.zip.\n",
            "       | Downloading package ycoe to /root/nltk_data...\n",
            "       |   Unzipping corpora/ycoe.zip.\n",
            "       | \n",
            "     Done downloading collection all\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categories = ['alt.atheism', 'soc.religion.christian',\n",
        "              'comp.graphics', 'sci.med']"
      ],
      "metadata": {
        "id": "_F4yhe0jqcj_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "twenty_train = fetch_20newsgroups(subset='train',\n",
        "    categories=categories, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "l_5cLOSmqsIF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twenty_train.target_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9OgyLQ5q0OP",
        "outputId": "f854de2e-0533-4875-ea6b-ea5cd650bb1b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-H7ZoY0uq2PS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import names\n",
        "labeled_names = ([(name, 'male') for name in names.words('male.txt')] + [(name, 'female') for name in names.words('female.txt')])\n",
        "import random\n",
        "random.shuffle(labeled_names)"
      ],
      "metadata": {
        "id": "funm9QMPucHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "featuresets = [(gender_features(n), gender) for (n, gender) in labeled_names]\n",
        "train_set, test_set = featuresets[500:], featuresets[:500]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)"
      ],
      "metadata": {
        "id": "hklX769JvVHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.classify(gender_features('Neo'))\n",
        "\n"
      ],
      "metadata": {
        "id": "329wy3RQvfG-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "88aa4de3-7615-4319-dcfc-7c4effcb109b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'male'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.classify(gender_features('Suma'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "mNvCKmu5vpWH",
        "outputId": "58d4e233-7762-45c8-ef3d-3bea08c6bbee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'female'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.classify(gender_features('Swati'))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "82451e5d-f6dd-45ed-ba73-8b4912fa3e41",
        "id": "E1de5QgSvrVb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'female'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.classify(gender_features('Srinivas'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-QHaDhxjvyzR",
        "outputId": "44c813ab-f044-4617-879f-753a0c162a4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'male'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(nltk.classify.accuracy(classifier, test_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsnuwbCmv2RU",
        "outputId": "bb998b1e-8c44-4b2b-de9a-19156b5c214f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.748\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.show_most_informative_features(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QVfxamKwhjU",
        "outputId": "d74b7bd4-05bf-43ac-aedd-507d08c077cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "             last_letter = 'k'              male : female =     45.2 : 1.0\n",
            "             last_letter = 'a'            female : male   =     33.1 : 1.0\n",
            "             last_letter = 'f'              male : female =     28.9 : 1.0\n",
            "             last_letter = 'p'              male : female =     12.6 : 1.0\n",
            "             last_letter = 'v'              male : female =      9.9 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choosing The Right Features"
      ],
      "metadata": {
        "id": "0TrRenT07b2Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gender_features2(name):\n",
        "    features = {}\n",
        "    features[\"first_letter\"] = name[0].lower()\n",
        "    features[\"last_letter\"] = name[-1].lower()\n",
        "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
        "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
        "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
        "    return features"
      ],
      "metadata": {
        "id": "0ucDu8wO7a6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gender_features2('John')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odTBJvmF8BRr",
        "outputId": "c6841e5c-95e9-40ab-c03d-4625b461b20b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'first_letter': 'j',\n",
              " 'last_letter': 'n',\n",
              " 'count(a)': 0,\n",
              " 'has(a)': False,\n",
              " 'count(b)': 0,\n",
              " 'has(b)': False,\n",
              " 'count(c)': 0,\n",
              " 'has(c)': False,\n",
              " 'count(d)': 0,\n",
              " 'has(d)': False,\n",
              " 'count(e)': 0,\n",
              " 'has(e)': False,\n",
              " 'count(f)': 0,\n",
              " 'has(f)': False,\n",
              " 'count(g)': 0,\n",
              " 'has(g)': False,\n",
              " 'count(h)': 1,\n",
              " 'has(h)': True,\n",
              " 'count(i)': 0,\n",
              " 'has(i)': False,\n",
              " 'count(j)': 1,\n",
              " 'has(j)': True,\n",
              " 'count(k)': 0,\n",
              " 'has(k)': False,\n",
              " 'count(l)': 0,\n",
              " 'has(l)': False,\n",
              " 'count(m)': 0,\n",
              " 'has(m)': False,\n",
              " 'count(n)': 1,\n",
              " 'has(n)': True,\n",
              " 'count(o)': 1,\n",
              " 'has(o)': True,\n",
              " 'count(p)': 0,\n",
              " 'has(p)': False,\n",
              " 'count(q)': 0,\n",
              " 'has(q)': False,\n",
              " 'count(r)': 0,\n",
              " 'has(r)': False,\n",
              " 'count(s)': 0,\n",
              " 'has(s)': False,\n",
              " 'count(t)': 0,\n",
              " 'has(t)': False,\n",
              " 'count(u)': 0,\n",
              " 'has(u)': False,\n",
              " 'count(v)': 0,\n",
              " 'has(v)': False,\n",
              " 'count(w)': 0,\n",
              " 'has(w)': False,\n",
              " 'count(x)': 0,\n",
              " 'has(x)': False,\n",
              " 'count(y)': 0,\n",
              " 'has(y)': False,\n",
              " 'count(z)': 0,\n",
              " 'has(z)': False}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gender_features2('Shiva')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvoyY03q8Gdq",
        "outputId": "573701cc-c9d5-478b-f199-0c755d3dbcde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'first_letter': 's',\n",
              " 'last_letter': 'a',\n",
              " 'count(a)': 1,\n",
              " 'has(a)': True,\n",
              " 'count(b)': 0,\n",
              " 'has(b)': False,\n",
              " 'count(c)': 0,\n",
              " 'has(c)': False,\n",
              " 'count(d)': 0,\n",
              " 'has(d)': False,\n",
              " 'count(e)': 0,\n",
              " 'has(e)': False,\n",
              " 'count(f)': 0,\n",
              " 'has(f)': False,\n",
              " 'count(g)': 0,\n",
              " 'has(g)': False,\n",
              " 'count(h)': 1,\n",
              " 'has(h)': True,\n",
              " 'count(i)': 1,\n",
              " 'has(i)': True,\n",
              " 'count(j)': 0,\n",
              " 'has(j)': False,\n",
              " 'count(k)': 0,\n",
              " 'has(k)': False,\n",
              " 'count(l)': 0,\n",
              " 'has(l)': False,\n",
              " 'count(m)': 0,\n",
              " 'has(m)': False,\n",
              " 'count(n)': 0,\n",
              " 'has(n)': False,\n",
              " 'count(o)': 0,\n",
              " 'has(o)': False,\n",
              " 'count(p)': 0,\n",
              " 'has(p)': False,\n",
              " 'count(q)': 0,\n",
              " 'has(q)': False,\n",
              " 'count(r)': 0,\n",
              " 'has(r)': False,\n",
              " 'count(s)': 1,\n",
              " 'has(s)': True,\n",
              " 'count(t)': 0,\n",
              " 'has(t)': False,\n",
              " 'count(u)': 0,\n",
              " 'has(u)': False,\n",
              " 'count(v)': 1,\n",
              " 'has(v)': True,\n",
              " 'count(w)': 0,\n",
              " 'has(w)': False,\n",
              " 'count(x)': 0,\n",
              " 'has(x)': False,\n",
              " 'count(y)': 0,\n",
              " 'has(y)': False,\n",
              " 'count(z)': 0,\n",
              " 'has(z)': False}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "featuresets = [(gender_features2(n), gender) for (n, gender) in labeled_names]\n",
        "train_set, test_set = featuresets[500:], featuresets[:500]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print(nltk.classify.accuracy(classifier, test_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0PU0WkQ8OBK",
        "outputId": "afe97460-4db5-44cb-b17c-c9d36d74f80f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_names = labeled_names[1500:]\n",
        "devtest_names = labeled_names[500:1500]\n",
        "test_names = labeled_names[:500]"
      ],
      "metadata": {
        "id": "1QKHlG6z8Xc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Having divided the corpus into appropriate datasets, we train a model using the training set [1], and then run it on the dev-test set [2]"
      ],
      "metadata": {
        "id": "as_LBKQe8pNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = [(gender_features(n), gender) for (n, gender) in train_names]\n",
        "devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]\n",
        "test_set = [(gender_features(n), gender) for (n, gender) in test_names]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print(nltk.classify.accuracy(classifier, devtest_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FpV0Ji98sSK",
        "outputId": "f5ff1588-c6fb-4f5f-b753-2756835626cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "errors = []\n",
        "for (name, tag) in devtest_names:\n",
        "    guess = classifier.classify(gender_features(name))\n",
        "    if guess != tag:\n",
        "             errors.append( (tag, guess, name) )"
      ],
      "metadata": {
        "id": "rjpTbLDt9CcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (tag, guess, name) in sorted(errors):\n",
        "  print('correct={:<8} guess={:<8s} name={:<30}'.format(tag, guess, name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9R-rye99TFQ",
        "outputId": "867717d4-b81e-4633-cb5e-79a654c85919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correct=female   guess=male     name=Abagael                       \n",
            "correct=female   guess=male     name=Abigael                       \n",
            "correct=female   guess=male     name=Aigneis                       \n",
            "correct=female   guess=male     name=Ardelis                       \n",
            "correct=female   guess=male     name=Arden                         \n",
            "correct=female   guess=male     name=Arlen                         \n",
            "correct=female   guess=male     name=Astrix                        \n",
            "correct=female   guess=male     name=Bidget                        \n",
            "correct=female   guess=male     name=Bill                          \n",
            "correct=female   guess=male     name=Bliss                         \n",
            "correct=female   guess=male     name=Bridgett                      \n",
            "correct=female   guess=male     name=Brit                          \n",
            "correct=female   guess=male     name=Brooks                        \n",
            "correct=female   guess=male     name=Brynn                         \n",
            "correct=female   guess=male     name=Caitrin                       \n",
            "correct=female   guess=male     name=Cameo                         \n",
            "correct=female   guess=male     name=Carlyn                        \n",
            "correct=female   guess=male     name=Carmen                        \n",
            "correct=female   guess=male     name=Carolann                      \n",
            "correct=female   guess=male     name=Cat                           \n",
            "correct=female   guess=male     name=Cathleen                      \n",
            "correct=female   guess=male     name=Cecil                         \n",
            "correct=female   guess=male     name=Christal                      \n",
            "correct=female   guess=male     name=Christin                      \n",
            "correct=female   guess=male     name=Chrysler                      \n",
            "correct=female   guess=male     name=Claribel                      \n",
            "correct=female   guess=male     name=Clovis                        \n",
            "correct=female   guess=male     name=Corabel                       \n",
            "correct=female   guess=male     name=Coral                         \n",
            "correct=female   guess=male     name=Dagmar                        \n",
            "correct=female   guess=male     name=Damaris                       \n",
            "correct=female   guess=male     name=Darryl                        \n",
            "correct=female   guess=male     name=Del                           \n",
            "correct=female   guess=male     name=Devan                         \n",
            "correct=female   guess=male     name=Diahann                       \n",
            "correct=female   guess=male     name=Dix                           \n",
            "correct=female   guess=male     name=Donnajean                     \n",
            "correct=female   guess=male     name=Doreen                        \n",
            "correct=female   guess=male     name=Doro                          \n",
            "correct=female   guess=male     name=Easter                        \n",
            "correct=female   guess=male     name=Estel                         \n",
            "correct=female   guess=male     name=Faun                          \n",
            "correct=female   guess=male     name=Fleur                         \n",
            "correct=female   guess=male     name=Floris                        \n",
            "correct=female   guess=male     name=Fran                          \n",
            "correct=female   guess=male     name=Frank                         \n",
            "correct=female   guess=male     name=Gill                          \n",
            "correct=female   guess=male     name=Gilligan                      \n",
            "correct=female   guess=male     name=Gladys                        \n",
            "correct=female   guess=male     name=Glenn                         \n",
            "correct=female   guess=male     name=Glyn                          \n",
            "correct=female   guess=male     name=Gretal                        \n",
            "correct=female   guess=male     name=Gwendolin                     \n",
            "correct=female   guess=male     name=Gwyn                          \n",
            "correct=female   guess=male     name=Harriet                       \n",
            "correct=female   guess=male     name=Harriott                      \n",
            "correct=female   guess=male     name=Jackelyn                      \n",
            "correct=female   guess=male     name=Jacquelynn                    \n",
            "correct=female   guess=male     name=Janet                         \n",
            "correct=female   guess=male     name=Jasmin                        \n",
            "correct=female   guess=male     name=Jen                           \n",
            "correct=female   guess=male     name=Jewell                        \n",
            "correct=female   guess=male     name=Joellyn                       \n",
            "correct=female   guess=male     name=Jonell                        \n",
            "correct=female   guess=male     name=Karalynn                      \n",
            "correct=female   guess=male     name=Karlen                        \n",
            "correct=female   guess=male     name=Karyl                         \n",
            "correct=female   guess=male     name=Katleen                       \n",
            "correct=female   guess=male     name=Keriann                       \n",
            "correct=female   guess=male     name=Kip                           \n",
            "correct=female   guess=male     name=Kristal                       \n",
            "correct=female   guess=male     name=Kristan                       \n",
            "correct=female   guess=male     name=Laureen                       \n",
            "correct=female   guess=male     name=Lauren                        \n",
            "correct=female   guess=male     name=Leann                         \n",
            "correct=female   guess=male     name=Lin                           \n",
            "correct=female   guess=male     name=Linet                         \n",
            "correct=female   guess=male     name=Linn                          \n",
            "correct=female   guess=male     name=Lorain                        \n",
            "correct=female   guess=male     name=Lulu                          \n",
            "correct=female   guess=male     name=Lynn                          \n",
            "correct=female   guess=male     name=Madelin                       \n",
            "correct=female   guess=male     name=Madlen                        \n",
            "correct=female   guess=male     name=Marabel                       \n",
            "correct=female   guess=male     name=Maren                         \n",
            "correct=female   guess=male     name=Margot                        \n",
            "correct=female   guess=male     name=Marilin                       \n",
            "correct=female   guess=male     name=Marilyn                       \n",
            "correct=female   guess=male     name=Marlyn                        \n",
            "correct=female   guess=male     name=Maryjo                        \n",
            "correct=female   guess=male     name=Maryl                         \n",
            "correct=female   guess=male     name=Maud                          \n",
            "correct=female   guess=male     name=Meagan                        \n",
            "correct=female   guess=male     name=Meg                           \n",
            "correct=female   guess=male     name=Meggan                        \n",
            "correct=female   guess=male     name=Michal                        \n",
            "correct=female   guess=male     name=Mikako                        \n",
            "correct=female   guess=male     name=Millisent                     \n",
            "correct=female   guess=male     name=Morgen                        \n",
            "correct=female   guess=male     name=Nadean                        \n",
            "correct=female   guess=male     name=Nanon                         \n",
            "correct=female   guess=male     name=Nert                          \n",
            "correct=female   guess=male     name=Noellyn                       \n",
            "correct=female   guess=male     name=Norean                        \n",
            "correct=female   guess=male     name=Pearl                         \n",
            "correct=female   guess=male     name=Persis                        \n",
            "correct=female   guess=male     name=Rachael                       \n",
            "correct=female   guess=male     name=Rachel                        \n",
            "correct=female   guess=male     name=Rianon                        \n",
            "correct=female   guess=male     name=Ros                           \n",
            "correct=female   guess=male     name=Rosalyn                       \n",
            "correct=female   guess=male     name=Rosamund                      \n",
            "correct=female   guess=male     name=Roselin                       \n",
            "correct=female   guess=male     name=Shannen                       \n",
            "correct=female   guess=male     name=Shell                         \n",
            "correct=female   guess=male     name=Susann                        \n",
            "correct=female   guess=male     name=Suzan                         \n",
            "correct=female   guess=male     name=Ted                           \n",
            "correct=female   guess=male     name=Van                           \n",
            "correct=female   guess=male     name=Violet                        \n",
            "correct=female   guess=male     name=Wandis                        \n",
            "correct=female   guess=male     name=Willow                        \n",
            "correct=male     guess=female   name=Abbie                         \n",
            "correct=male     guess=female   name=Amery                         \n",
            "correct=male     guess=female   name=Andre                         \n",
            "correct=male     guess=female   name=Archie                        \n",
            "correct=male     guess=female   name=Aube                          \n",
            "correct=male     guess=female   name=Aubrey                        \n",
            "correct=male     guess=female   name=Augustine                     \n",
            "correct=male     guess=female   name=Barclay                       \n",
            "correct=male     guess=female   name=Barri                         \n",
            "correct=male     guess=female   name=Bay                           \n",
            "correct=male     guess=female   name=Benny                         \n",
            "correct=male     guess=female   name=Bernie                        \n",
            "correct=male     guess=female   name=Bertie                        \n",
            "correct=male     guess=female   name=Blare                         \n",
            "correct=male     guess=female   name=Brodie                        \n",
            "correct=male     guess=female   name=Cammy                         \n",
            "correct=male     guess=female   name=Cody                          \n",
            "correct=male     guess=female   name=Corby                         \n",
            "correct=male     guess=female   name=Cory                          \n",
            "correct=male     guess=female   name=Courtney                      \n",
            "correct=male     guess=female   name=Dabney                        \n",
            "correct=male     guess=female   name=Davey                         \n",
            "correct=male     guess=female   name=Davidde                       \n",
            "correct=male     guess=female   name=Davide                        \n",
            "correct=male     guess=female   name=Derby                         \n",
            "correct=male     guess=female   name=Dimitry                       \n",
            "correct=male     guess=female   name=Dwaine                        \n",
            "correct=male     guess=female   name=Dwane                         \n",
            "correct=male     guess=female   name=Edie                          \n",
            "correct=male     guess=female   name=Emmy                          \n",
            "correct=male     guess=female   name=Franky                        \n",
            "correct=male     guess=female   name=Freddie                       \n",
            "correct=male     guess=female   name=Friedrich                     \n",
            "correct=male     guess=female   name=Gabe                          \n",
            "correct=male     guess=female   name=Garvey                        \n",
            "correct=male     guess=female   name=Gene                          \n",
            "correct=male     guess=female   name=Giffie                        \n",
            "correct=male     guess=female   name=Hamish                        \n",
            "correct=male     guess=female   name=Heath                         \n",
            "correct=male     guess=female   name=Helmuth                       \n",
            "correct=male     guess=female   name=Henri                         \n",
            "correct=male     guess=female   name=Hervey                        \n",
            "correct=male     guess=female   name=Hugh                          \n",
            "correct=male     guess=female   name=Hurley                        \n",
            "correct=male     guess=female   name=Ike                           \n",
            "correct=male     guess=female   name=Isadore                       \n",
            "correct=male     guess=female   name=Jere                          \n",
            "correct=male     guess=female   name=Jerrome                       \n",
            "correct=male     guess=female   name=Jessee                        \n",
            "correct=male     guess=female   name=Jimmy                         \n",
            "correct=male     guess=female   name=Johnnie                       \n",
            "correct=male     guess=female   name=Jory                          \n",
            "correct=male     guess=female   name=Joseph                        \n",
            "correct=male     guess=female   name=Keith                         \n",
            "correct=male     guess=female   name=Kennedy                       \n",
            "correct=male     guess=female   name=Kingsley                      \n",
            "correct=male     guess=female   name=Lay                           \n",
            "correct=male     guess=female   name=Lefty                         \n",
            "correct=male     guess=female   name=Lemmy                         \n",
            "correct=male     guess=female   name=Lonnie                        \n",
            "correct=male     guess=female   name=Luigi                         \n",
            "correct=male     guess=female   name=Luke                          \n",
            "correct=male     guess=female   name=Marty                         \n",
            "correct=male     guess=female   name=Mattie                        \n",
            "correct=male     guess=female   name=Murray                        \n",
            "correct=male     guess=female   name=Nealy                         \n",
            "correct=male     guess=female   name=Nevile                        \n",
            "correct=male     guess=female   name=Noah                          \n",
            "correct=male     guess=female   name=Osborne                       \n",
            "correct=male     guess=female   name=Ossie                         \n",
            "correct=male     guess=female   name=Patrice                       \n",
            "correct=male     guess=female   name=Randy                         \n",
            "correct=male     guess=female   name=Rawley                        \n",
            "correct=male     guess=female   name=Rene                          \n",
            "correct=male     guess=female   name=Rich                          \n",
            "correct=male     guess=female   name=Richy                         \n",
            "correct=male     guess=female   name=Ritchie                       \n",
            "correct=male     guess=female   name=Rodge                         \n",
            "correct=male     guess=female   name=Saxe                          \n",
            "correct=male     guess=female   name=Shelley                       \n",
            "correct=male     guess=female   name=Shorty                        \n",
            "correct=male     guess=female   name=Si                            \n",
            "correct=male     guess=female   name=Smith                         \n",
            "correct=male     guess=female   name=Sparky                        \n",
            "correct=male     guess=female   name=Sunny                         \n",
            "correct=male     guess=female   name=Teddy                         \n",
            "correct=male     guess=female   name=Terry                         \n",
            "correct=male     guess=female   name=Thorpe                        \n",
            "correct=male     guess=female   name=Tommy                         \n",
            "correct=male     guess=female   name=Torrence                      \n",
            "correct=male     guess=female   name=Trey                          \n",
            "correct=male     guess=female   name=Troy                          \n",
            "correct=male     guess=female   name=Tucky                         \n",
            "correct=male     guess=female   name=Ty                            \n",
            "correct=male     guess=female   name=Uri                           \n",
            "correct=male     guess=female   name=Verney                        \n",
            "correct=male     guess=female   name=Vince                         \n",
            "correct=male     guess=female   name=Vite                          \n",
            "correct=male     guess=female   name=Wallie                        \n",
            "correct=male     guess=female   name=Ware                          \n",
            "correct=male     guess=female   name=Witty                         \n",
            "correct=male     guess=female   name=Woody                         \n",
            "correct=male     guess=female   name=Yancey                        \n",
            "correct=male     guess=female   name=Zachery                       \n",
            "correct=male     guess=female   name=Zollie                        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gender_features(word):\n",
        "     return {'suffix1': word[-1:],\n",
        "             'suffix2': word[-2:]}"
      ],
      "metadata": {
        "id": "BkETv3-29cCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = [(gender_features(n), gender) for (n, gender) in train_names]\n",
        "devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print(nltk.classify.accuracy(classifier, devtest_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbQz4cpm9hlr",
        "outputId": "9b5ce5c9-3aeb-413e-998c-a7886dad5ddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xeL4K3_kyD7"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.model_selection import train_test_split # function for splitting data to train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.classify import SklearnClassifier"
      ],
      "metadata": {
        "id": "wt3TTXMkolkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud,STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "_8vFw2HAotFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output"
      ],
      "metadata": {
        "id": "6iqndG0Joumw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('../input/Sentiment.csv')\n",
        "# Keeping only the neccessary columns\n",
        "data = data[['text','sentiment']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "oq2Zp0PLozX7",
        "outputId": "1f2363a9-aca6-4a2f-b0e8-d058f57966ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-7a8fca301a44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/Sentiment.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Keeping only the neccessary columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/Sentiment.csv'"
          ]
        }
      ]
    }
  ]
}